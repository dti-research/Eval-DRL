algorithm:
  class: train
  codebase:
    class: learn
    module: baselines.trpo_mpi.trpo_mpi
  hyperparameters:
    batch_size: 8192
    cg_damping: 0.1
    cg_iters: 10
    gamma: 0.97433
    hid_size: 64
    lam: 0.99647
    max_kl: 0.02437
    max_timesteps: 150000
    num_hid_layers: 4
    optim_batchsize: null
    optim_stepsize: null
    timesteps_per_batch: 4096
    vf_iters: 5
    vf_stepsize: 0.00472
  module: algorithms/trpo
environment:
  class: get_env
  codebase:
    class: ReacherEnv
    module: senseact.envs.ur.reacher_env
  module: environments/ur
  parameters:
    accel_max: 1.4
    actuation_sync_period: 1
    control_type: velocity
    delay: 0.0
    deriv_action_max: 5
    derivative_type: none
    dof: 2
    dt: 0.04
    episode_length_step: null
    episode_length_time: 4.0
    first_deriv_max: 2
    host: null
    movej_t: 2.0
    reset_type: zero
    reward_type: precision
    rllab_box: false
    run_mode: multiprocess
    speed_max: 0.3
    speedj_a: 1.4
    target_type: position
  setup:
    class: setup
    module: utils/ur5_setup
global:
  seed:
    high: null
    low: null
model:
  class: MlpPolicy
  module: baselines.ppo1.mlp_policy
train:
  artifact_path: artifacts/logs/trpo/2
